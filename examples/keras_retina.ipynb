{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using retinanet backend\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "import yolk\n",
    "from PIL import Image\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np \n",
    "from utils.show_bbox_plt import draw_bounding_boxes_on_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    _BACKEND = 'retinanet'\n",
    "    image_paths = ['./twice.jpg', './000000008021.jpg']\n",
    "    images = []\n",
    "    preprocess_images = []\n",
    "    results = []\n",
    "    class_info = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "    \n",
    "    ## load image & preprocess image\n",
    "    for each_path in image_paths: \n",
    "        loaded_image, preprocessed_image = yolk.detector.preprocess_image(each_path)\n",
    "        \n",
    "        images.append(loaded_image)\n",
    "        preprocess_images.append(preprocessed_image)\n",
    "    \n",
    "    ## load model\n",
    "    model_path = os.path.join('..', 'snapshots', 'resnet50_coco_best_v2.1.0.h5')\n",
    "    model = yolk.detector.load_inference_model(model_path, 'resnet50')\n",
    "\n",
    "    for each_preprocess_image in preprocess_images:\n",
    "        ## model predict\n",
    "        output = model.predict_on_batch(np.expand_dims(each_preprocess_image, axis=0))\n",
    "        \n",
    "        ## postprocess\n",
    "        result = yolk.detector.postprocess_image(output, class_info)\n",
    "        results.append(result)     \n",
    "        \n",
    "    ## draw images\n",
    "    draw_bounding_boxes_on_images(images, results, class_info, thresold=0.5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dlawo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlawo\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300, 6)\n",
      "[[[ 1.00000000e+00  8.41746271e-01  6.89757874e+02  2.42585846e+02\n",
      "    9.72602417e+02  7.59914551e+02]\n",
      "  [ 1.00000000e+00  8.32300246e-01  1.25002403e+01  5.23198814e+01\n",
      "    3.50522797e+02  7.62029907e+02]\n",
      "  [ 1.00000000e+00  7.34139919e-01  3.49540741e+02  2.18567947e+02\n",
      "    7.28291870e+02  7.94829956e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      "   -1.00000000e+00 -1.00000000e+00]\n",
      "  [ 0.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      "   -1.00000000e+00 -1.00000000e+00]\n",
      "  [ 0.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      "   -1.00000000e+00 -1.00000000e+00]]]\n",
      "segmentation_0\n",
      "segmentation_1\n",
      "segmentation_2\n",
      "segmentation_3\n",
      "segmentation_4\n",
      "segmentation_5\n",
      "segmentation_6\n",
      "segmentation_7\n",
      "(1, 300, 6)\n",
      "[[[ 1.00000000e+00  9.68111873e-01  4.09019653e+02  1.67141815e+02\n",
      "    7.28081665e+02  6.03420349e+02]\n",
      "  [ 1.00000000e+00  8.35583985e-01  5.06820679e-02  4.26605316e+02\n",
      "    5.12541138e+02  7.85832397e+02]\n",
      "  [ 1.00000000e+00  7.23440826e-01  7.23494690e+02  4.75749359e+02\n",
      "    1.06700000e+03  7.91431030e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      "   -1.00000000e+00 -1.00000000e+00]\n",
      "  [ 0.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      "   -1.00000000e+00 -1.00000000e+00]\n",
      "  [ 0.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      "   -1.00000000e+00 -1.00000000e+00]]]\n",
      "segmentation_0\n",
      "segmentation_1\n",
      "segmentation_2\n",
      "segmentation_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
